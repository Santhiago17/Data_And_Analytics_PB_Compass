{
	"jobConfig": {
		"name": "refined_filmes_tmdb",
		"description": "",
		"role": "arn:aws:iam::009160030622:role/service-role/AWSGlueServiceRole",
		"command": "glueetl",
		"version": "4.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 2,
		"maxCapacity": 2,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "refined_filmes_tmdb.py",
		"scriptLocation": "s3://aws-glue-assets-009160030622-us-east-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2024-10-14T18:41:42.013Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-009160030622-us-east-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-009160030622-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.sql import functions as F\r\n\r\n# Inicializa o GlueContext\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\n\r\n# Caminhos dos arquivos\r\ninput_path = 's3://data-lake-santhiago-santos/Trusted/TMDB/parquet/2024/10/14/'\r\noutput_base_path = 's3://data-lake-santhiago-santos/Refined/TMDB/parquet/2024/10/14/'\r\n\r\n# 1. Ler os dados do Parquet\r\ndf_fatos = spark.read.parquet(input_path)\r\n\r\n# 2. Tratar os dados de revenue e budget\r\ndf_fatos = df_fatos.withColumn('budget', F.col('budget').cast('double'))\r\ndf_fatos = df_fatos.withColumn('revenue', F.col('revenue').cast('double'))\r\n\r\n# 3. Criar a Dimensao_Atores\r\ndim_atores = df_fatos.select('ator_id', 'ator_nome', 'ator_personagem', 'ator_popularity').dropDuplicates()\r\n\r\n# 4. Criar a Dimensao_Genero\r\ndim_genero = df_fatos.select(F.explode(F.split('genres', ',')).alias('genero')).dropDuplicates() \\\r\n    .withColumn('genero_id', F.monotonically_increasing_id())\r\n\r\n# 5. Criar a Dimensao_Produtora\r\ndim_produtora = df_fatos.select(F.explode(F.split('production_companies', ',')).alias('produtora')).dropDuplicates() \\\r\n    .withColumn('produtora_id', F.monotonically_increasing_id())\r\n\r\n# 6. Criar a Dimensao_Data\r\ndf_fatos = df_fatos.withColumn('release_date', F.to_date('release_date'))\r\ndim_data = df_fatos.select('release_date').dropDuplicates() \\\r\n    .withColumn('data_id', F.monotonically_increasing_id()) \\\r\n    .withColumn('ano', F.year('release_date')) \\\r\n    .withColumn('mes', F.month('release_date')) \\\r\n    .withColumn('dia', F.dayofmonth('release_date')) \\\r\n    .withColumn('trimestre', (F.floor((F.month('release_date') - 1) / 3) + 1).cast('int'))\r\n\r\n# 7. Preparar a tabela fato\r\nfato_filmes = df_fatos.select(\r\n    F.col('id').alias('filme_id'),\r\n    'budget',\r\n    'revenue',\r\n    'popularity',\r\n    'vote_average',\r\n    'vote_count',\r\n    'release_date'\r\n)\r\n\r\n# 8. Salvar as tabelas em Parquet\r\ndim_atores.write.mode('overwrite').parquet(output_base_path + 'dim_atores/')\r\ndim_genero.write.mode('overwrite').parquet(output_base_path + 'dim_genero/')\r\ndim_produtora.write.mode('overwrite').parquet(output_base_path + 'dim_produtora/')\r\ndim_data.write.mode('overwrite').parquet(output_base_path + 'dim_data/')\r\nfato_filmes.write.mode('overwrite').parquet(output_base_path + 'fato_filmes/')\r\n"
}